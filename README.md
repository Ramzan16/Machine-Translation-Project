# Machine Translation Project

This is my attempt at creating a transformer for machine translation inspired from the "Attention is All You Need" Paper. In this project, I have created a transformer model and trained it for the task of translating German text into English. \
\
The details of the project are on this website - <a href="https://ramzan16.github.io/Machine-Translation-Project/" target="_blank">https://ramzan16.github.io/Machine-Translation-Project/</a>

## Resources:
The following is a list of all the resources that helped me get a better understanding of how attention, feed forward layers and other components of a transformer work:
1. [3Blue1Brown's playlist on Neural Networks and LLMs](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
2. [Michael Neilson's book on Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)
3. [Andrej Karpathy's Zero to Hero YouTube Playlist](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
4. [Attention is All You Need Paper](https://arxiv.org/abs/1706.03762)
